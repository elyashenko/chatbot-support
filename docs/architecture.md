# Архитектура RAG Chatbot Support System

## 🏗️ Общая архитектура

Система построена по принципу **RAG (Retrieval-Augmented Generation)** - это современный подход к созданию ИИ-ассистентов, который сочетает поиск по базе знаний с генерацией ответов.

```
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   Frontend      │    │    Backend      │    │  Vector Store   │
│   (React)       │◄──►│   (FastAPI)     │◄──►│   (ChromaDB)    │
└─────────────────┘    └─────────────────┘    └─────────────────┘
         │                       │                       │
         │                       │                       │
         ▼                       ▼                       ▼
┌─────────────────┐    ┌─────────────────┐    ┌─────────────────┐
│   WebSocket     │    │   PostgreSQL    │    │  Embeddings     │
│   Connection    │    │   Database      │    │   Model         │
└─────────────────┘    └─────────────────┘    └─────────────────┘
```

## 🔄 Как работает RAG

### 1. **Индексация документов**
```
Документ → Разбиение на чанки → Векторизация → Сохранение в ChromaDB
```

### 2. **Обработка запроса пользователя**
```
Вопрос → Векторизация → Поиск похожих чанков → Контекст + Вопрос → LLM → Ответ
```

### 3. **Детальный процесс**

#### Шаг 1: Векторизация вопроса
- Пользователь задает вопрос
- Система преобразует вопрос в вектор с помощью модели `sentence-transformers`
- Используется модель `all-MiniLM-L6-v2` (быстрая и эффективная)

#### Шаг 2: Поиск релевантного контекста
- Система ищет в векторной базе чанки, похожие на вопрос
- Применяется **гибридный поиск**:
  - **Векторный поиск**: по семантическому сходству
  - **Ключевой поиск**: по точным совпадениям слов
- Возвращается топ-5 наиболее релевантных чанков

#### Шаг 3: Конструирование промпта
```
Система: Ты - эксперт по поддержке разработчиков. 
Используй только предоставленную информацию для ответа.

Контекст:
[Чанк 1: релевантная информация]
[Чанк 2: дополнительная информация]
...

Вопрос пользователя: [вопрос]

Ответь на основе контекста. Если информации недостаточно, 
скажи об этом честно.
```

#### Шаг 4: Генерация ответа
- Промпт отправляется в выбранную LLM модель
- Система поддерживает несколько провайдеров:
  - **GigaChat** (основная модель)
  - **DeepSeek** (резервная)
  - **OpenAI** (резервная)
- Если основная модель недоступна, автоматически переключается на резервную

#### Шаг 5: Сохранение и обратная связь
- Вопрос и ответ сохраняются в PostgreSQL
- Пользователь может оценить качество ответа
- Система учится на обратной связи

## 🧠 Ключевые компоненты

### 1. **Embedding Model (`sentence-transformers`)**
- **Модель**: `all-MiniLM-L6-v2`
- **Размерность**: 384
- **Скорость**: ~2000 предложений/сек
- **Качество**: 85% точность на тестах семантического сходства

### 2. **Vector Store (ChromaDB)**
- **Тип**: In-memory с персистентностью
- **Метрика**: Cosine similarity
- **Индексация**: HNSW (Hierarchical Navigable Small World)
- **Хранение**: Локальная папка `./chroma_db`

### 3. **Document Chunking**
- **Размер чанка**: 1000 символов
- **Перекрытие**: 200 символов
- **Стратегия**: По предложениям с сохранением контекста

### 4. **Hybrid Search**
```python
def hybrid_search(query: str, top_k: int = 5):
    # 1. Векторный поиск (70% веса)
    vector_results = vector_search(query, top_k * 2)
    
    # 2. Ключевой поиск (30% веса)
    keyword_results = keyword_search(query, top_k * 2)
    
    # 3. Объединение и ранжирование
    combined = merge_and_rank(vector_results, keyword_results)
    
    return combined[:top_k]
```

## 🔌 API Endpoints

### REST API
- `POST /api/chat/message` - Отправка сообщения
- `GET /api/chat/sessions` - Список сессий
- `GET /api/chat/sessions/{id}` - Детали сессии
- `GET /api/chat/models` - Доступные модели
- `GET /api/chat/stats` - Статистика системы

### WebSocket
- `ws://localhost:8000/ws/chat` - Реальное время чата
- `ws://localhost:8000/ws/status` - Статус соединения

## 🗄️ База данных

### Таблицы PostgreSQL
1. **users** - Пользователи системы
2. **chat_sessions** - Сессии чата
3. **chat_messages** - Сообщения в сессиях
4. **feedback** - Оценки ответов
5. **knowledge_documents** - Метаданные документов
6. **system_metrics** - Метрики производительности

### Схема данных
```sql
-- Сессия чата
chat_sessions (
    id UUID PRIMARY KEY,
    user_id UUID REFERENCES users(id),
    title VARCHAR(255),
    created_at TIMESTAMP,
    updated_at TIMESTAMP
)

-- Сообщения
chat_messages (
    id UUID PRIMARY KEY,
    session_id UUID REFERENCES chat_sessions(id),
    content TEXT,
    role ENUM('user', 'assistant'),
    created_at TIMESTAMP,
    feedback_score INTEGER
)
```

## 🚀 Производительность

### Ожидаемые метрики
- **Время ответа**: < 2 секунды
- **Точность ответов**: 85-90%
- **Покрытие вопросов**: 70-80%
- **Параллельные запросы**: 100+

### Оптимизации
1. **Кэширование**: Redis для частых запросов
2. **Асинхронность**: FastAPI + async/await
3. **Векторизация**: Batch processing документов
4. **Индексация**: HNSW для быстрого поиска

## 🔧 Конфигурация

### Ключевые параметры
```env
# Размер чанков
CHUNK_SIZE=1000
CHUNK_OVERLAP=200

# Поиск
TOP_K_RESULTS=5
SIMILARITY_THRESHOLD=0.7

# Модели
DEFAULT_MODEL=gigachat
FALLBACK_MODELS=["deepseek", "openai"]
```

## 📊 Мониторинг

### Метрики
- Количество обработанных запросов
- Среднее время ответа
- Точность ответов (по feedback)
- Размер векторной базы
- Использование моделей

### Логирование
- Структурированные логи с `loguru`
- Уровни: DEBUG, INFO, WARNING, ERROR
- Ротация логов по размеру и времени

## 🔒 Безопасность

### Аутентификация
- JWT токены
- Время жизни: 30 минут
- Алгоритм: HS256

### Авторизация
- Роли пользователей
- Ограничения на API
- Rate limiting: 60 запросов/минута

### Защита данных
- Шифрование API ключей
- Изоляция пользователей
- Логирование доступа

## 🚀 Масштабирование

### Горизонтальное масштабирование
- Множественные инстансы FastAPI
- Load balancer (Nginx)
- Shared PostgreSQL
- Redis cluster

### Вертикальное масштабирование
- Увеличение ресурсов сервера
- Оптимизация запросов
- Индексы базы данных
- Кэширование

## 🔄 Жизненный цикл документа

1. **Загрузка** → Confluence API / файлы
2. **Предобработка** → Очистка, форматирование
3. **Чанкирование** → Разбиение на части
4. **Векторизация** → Преобразование в векторы
5. **Индексация** → Сохранение в ChromaDB
6. **Поиск** → Поиск по векторам
7. **Обновление** → Периодическая синхронизация

## 💡 Лучшие практики

### Для документов
- Размер: 1000-2000 символов на чанк
- Качество: Актуальная и точная информация
- Структура: Логическая группировка
- Метаданные: Теги, категории, версии

### Для промптов
- Контекст: Достаточная информация
- Инструкции: Четкие указания для LLM
- Ограничения: Что можно и нельзя делать
- Примеры: Конкретные случаи использования

### Для развертывания
- Окружения: Dev, Staging, Production
- Мониторинг: Prometheus + Grafana
- Логирование: ELK Stack
- Backup: Автоматическое резервное копирование
